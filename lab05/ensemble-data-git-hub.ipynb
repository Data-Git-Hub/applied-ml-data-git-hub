{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de3b2b2",
   "metadata": {},
   "source": [
    "# Predicting Red Wine Quality Using Ensemble Machine Learning Models\n",
    "\n",
    "Author: Data-Git-Hub <br>\n",
    "GitHub Project Repository Link: https://github.com/Data-Git-Hub/applied-ml-data-git-hub <br>\n",
    "Dataset Link: https://archive.ics.uci.edu/ml/datasets/Wine+Quality <br>\n",
    "15 April 2025 <br>\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This project investigates the use of ensemble machine learning methods to classify the quality of red wine based on physicochemical properties. Ensemble models integrate the predictions of multiple base estimators to improve overall model performance and generalization. Techniques such as Random Forests, AdaBoost, Gradient Boosting, and Voting Classifiers are commonly employed to address the limitations of single-model approaches, particularly in reducing overfitting and increasing predictive reliability. <br>\n",
    "\n",
    "The dataset used in this analysis is sourced from the UCI Machine Learning Repository and was originally compiled by Cortez, Cerdeira, Almeida, Matos, and Reis (2009). It contains various physicochemical attributes of red wine samples, such as fixed acidity, residual sugar, pH, alcohol content, and sulfur dioxide levels. Each sample includes a corresponding quality rating, evaluated by wine tasters on a scale from 0 to 10. To simplify the classification task, the original numerical ratings were categorized into three discrete classes: low, medium, and high quality. <br>\n",
    "\n",
    "The objective of the analysis is to evaluate and compare multiple ensemble classification techniques using a range of performance metrics, including accuracy, precision, recall, and F1 score. The results are used to determine which models are most effective in predicting wine quality and to identify the trade-offs between model complexity and generalization. <br>\n",
    "\n",
    "### Imports\n",
    "Python libraries are collections of pre-written code that provide specific functionalities, making programming more efficient and reducing the need to write code from scratch. These libraries cover a wide range of applications, including data analysis, machine learning, web development, and automation. Some libraries, such as os, sys, math, json, and datetime, come built-in with Python as part of its standard library, providing essential functions for file handling, system operations, mathematical computations, and data serialization. Other popular third-party libraries, like pandas, numpy, matplotlib, seaborn, and scikit-learn, must be installed separately and are widely used in data science and machine learning. The extensive availability of libraries in Python's ecosystem makes it a versatile and powerful programming language for various domains. <br>\n",
    "\n",
    "Pandas is a powerful data manipulation and analysis library that provides flexible data structures, such as DataFrames and Series. It is widely used for handling structured datasets, enabling easy data cleaning, transformation, and aggregation. Pandas is essential for data preprocessing in machine learning and statistical analysis. <br>\n",
    "https://pandas.pydata.org/docs/ <br>\n",
    "\n",
    "NumPy (Numerical Python) is a foundational library for numerical computing in Python. It provides support for large, multi-dimensional arrays and matrices, along with a comprehensive collection of mathematical functions to operate on these arrays efficiently. NumPy is a key component in scientific computing and machine learning. <br>\n",
    "https://numpy.org/doc/stable/ <br>\n",
    "\n",
    "Matplotlib is a widely used data visualization library that allows users to create static, animated, and interactive plots. It provides extensive tools for generating various chart types, including line plots, scatter plots, histograms, and bar charts, making it a critical library for exploratory data analysis. <br>\n",
    "https://matplotlib.org/stable/contents.html <br>\n",
    "\n",
    "Seaborn is a statistical data visualization library built on top of Matplotlib, designed for creating visually appealing and informative plots. It simplifies complex visualizations, such as heatmaps, violin plots, and pair plots, making it easier to identify patterns and relationships in datasets. <br>\n",
    "https://seaborn.pydata.org/ <br>\n",
    "\n",
    "Scikit-learn provides a variety of tools for machine learning, including data preprocessing, model selection, and evaluation. It contains essential functions for building predictive models and analyzing datasets. <br>\n",
    "sklearn.metrics: This module provides various performance metrics for evaluating machine learning models. <br>\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766c0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning imports\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, PolynomialFeatures, MinMaxScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, mean_absolute_error, mean_squared_error, r2_score, precision_score, recall_score, f1_score, classification_report, silhouette_score, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFECV, RFE, SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Fully disable output truncation in Jupyter (for VS Code)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9226c26",
   "metadata": {},
   "source": [
    "### Section 1. Load and Inspect the Data\n",
    "\n",
    "# Load the dataset (download from UCI and save in the same folder)\n",
    "df = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "\n",
    "# Display structure and first few rows\n",
    "df.info()\n",
    "df.head()\n",
    "\n",
    "# The dataset includes 11 physicochemical input variables (features):\n",
    "# ---------------------------------------------------------------\n",
    "# - fixed acidity          mostly tartaric acid\n",
    "# - volatile acidity       mostly acetic acid (vinegar)\n",
    "# - citric acid            can add freshness and flavor\n",
    "# - residual sugar         remaining sugar after fermentation\n",
    "# - chlorides              salt content\n",
    "# - free sulfur dioxide    protects wine from microbes\n",
    "# - total sulfur dioxide   sum of free and bound forms\n",
    "# - density                related to sugar content\n",
    "# - pH                     acidity level (lower = more acidic)\n",
    "# - sulphates              antioxidant and microbial stabilizer\n",
    "# - alcohol                % alcohol by volume\n",
    "\n",
    "# The target variable is:\n",
    "# - quality (integer score from 0 to 10, rated by wine tasters)\n",
    "\n",
    "# We will simplify this target into three categories:\n",
    "#   - low (3–4), medium (5–6), high (7–8) to make classification feasible.\n",
    "#   - we will also make this numeric (we want both for clarity)\n",
    "# The dataset contains 1599 samples and 12 columns (11 features + target).\n",
    "\n",
    "# Load spiral dataset\n",
    "spiral = pd.read_csv(\"spiral.csv\")\n",
    "\n",
    "# Display basic information\n",
    "spiral.info()\n",
    "\n",
    "# Display first few rows\n",
    "print(spiral.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be404c8",
   "metadata": {},
   "source": [
    "### Section 2. Prepare the Data\n",
    "\n",
    "# Includes cleaning, feature engineering, encoding, splitting, helper functions\n",
    "# Define helper function that:\n",
    "\n",
    "# Takes one input, the quality (which we will temporarily name q while in the function)\n",
    "# And returns a string of the quality label (low, medium, high)\n",
    "# This function will be used to create the quality_label column\n",
    "def quality_to_label(q):\n",
    "    if q <= 4:\n",
    "        return \"low\"\n",
    "    elif q <= 6:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "\n",
    "# Call the apply() method on the quality column to create the new quality_label column\n",
    "df[\"quality_label\"] = df[\"quality\"].apply(quality_to_label)\n",
    "\n",
    "\n",
    "# Then, create a numeric column for modeling: 0 = low, 1 = medium, 2 = high\n",
    "def quality_to_number(q):\n",
    "    if q <= 4:\n",
    "        return 0\n",
    "    elif q <= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "df[\"quality_numeric\"] = df[\"quality\"].apply(quality_to_number)\n",
    "\n",
    "# Explain what we do and why as you proceed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2f5c5b",
   "metadata": {},
   "source": [
    "### Section 3. Feature Selection and Justification \n",
    "\n",
    "# Define input features (X) and target (y)\n",
    "# Features: all columns except 'quality' and 'quality_label' and 'quality_numberic' - drop these from the input array\n",
    "# Target: quality_label (the new column we just created)\n",
    "X = df.drop(columns=[\"quality\", \"quality_label\", \"quality_numeric\"])  # Features\n",
    "y = df[\"quality_numeric\"]  # Target\n",
    "\n",
    "# Explain / introduce your choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac6b33e",
   "metadata": {},
   "source": [
    "### Section 4. Split the Data into Train and Test\n",
    "\n",
    "# Train/test split (stratify to preserve class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b9739a",
   "metadata": {},
   "source": [
    "### Section 5.  Evaluate Model Performance (Choose 2)\n",
    "Below is a list of  9 model variations. Choose two to focus on for your comparison. \n",
    "\n",
    "Option\tModel Name\tNotes\n",
    "1\tRandom Forest (100)\tA strong baseline model using 100 decision trees.\n",
    "2\tRandom Forest (200, max_depth=10)\tAdds more trees, but limits tree depth to reduce overfitting.\n",
    "3\tAdaBoost (100)\tBoosting method that focuses on correcting previous errors.\n",
    "4\tAdaBoost (200, lr=0.5)\tMore iterations and slower learning for better generalization.\n",
    "5\tGradient Boosting (100)\tBoosting approach using gradient descent.\n",
    "6\tVoting (DT + SVM + NN)\tCombines diverse models by averaging their predictions.\n",
    "7\tVoting (RF + LR + KNN)\tAnother mix of different model types.\n",
    "8\tBagging (DT, 100)\tBuilds many trees in parallel on different samples.\n",
    "9\tMLP Classifier\tA basic neural network with one hidden layer.\n",
    " \n",
    "\n",
    "Here's a helper function that might be nice - feel free to use or adjust as you like. \n",
    "\n",
    "\n",
    "# Helper function to train and evaluate models\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, results):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average=\"weighted\")\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(\"Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"Train Accuracy\": train_acc,\n",
    "            \"Test Accuracy\": test_acc,\n",
    "            \"Train F1\": train_f1,\n",
    "            \"Test F1\": test_f1,\n",
    "        }\n",
    "    )\n",
    "Here's how to create the different types of ensemble models listed above (you don't need to do all of them yourself. Choose 2 - we have a whole team working on this.)\n",
    "\n",
    "results = []\n",
    "\n",
    "# 1. Random Forest\n",
    "evaluate_model(\n",
    "    \"Random Forest (100)\",\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 2. Random Forest (200, max depth=10) \n",
    "evaluate_model(\n",
    "    \"Random Forest (200, max_depth=10)\",\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 3. AdaBoost \n",
    "evaluate_model(\n",
    "    \"AdaBoost (100)\",\n",
    "    AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 4. AdaBoost (200, lr=0.5) \n",
    "evaluate_model(\n",
    "    \"AdaBoost (200, lr=0.5)\",\n",
    "    AdaBoostClassifier(n_estimators=200, learning_rate=0.5, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 5. Gradient Boosting\n",
    "evaluate_model(\n",
    "    \"Gradient Boosting (100)\",\n",
    "    GradientBoostingClassifier(\n",
    "        n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42\n",
    "    ),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 6. Voting Classifier (DT, SVM, NN) \n",
    "voting1 = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"DT\", DecisionTreeClassifier()),\n",
    "        (\"SVM\", SVC(probability=True)),\n",
    "        (\"NN\", MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000)),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "evaluate_model(\n",
    "    \"Voting (DT + SVM + NN)\", voting1, X_train, y_train, X_test, y_test, results\n",
    ")\n",
    "\n",
    "# 7. Voting Classifier (RF, LR, KNN) \n",
    "voting2 = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"RF\", RandomForestClassifier(n_estimators=100)),\n",
    "        (\"LR\", LogisticRegression(max_iter=1000)),\n",
    "        (\"KNN\", KNeighborsClassifier()),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "evaluate_model(\n",
    "    \"Voting (RF + LR + KNN)\", voting2, X_train, y_train, X_test, y_test, results\n",
    ")\n",
    "\n",
    "# 8. Bagging \n",
    "evaluate_model(\n",
    "    \"Bagging (DT, 100)\",\n",
    "    BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42\n",
    "    ),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 9. MLP Classifier \n",
    "evaluate_model(\n",
    "    \"MLP Classifier\",\n",
    "    MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254d9b52",
   "metadata": {},
   "source": [
    "### Section 6. Compare Results \n",
    "# Create a table of results \n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nSummary of All Models:\")\n",
    "display(results_df)\n",
    "\n",
    "# Recommendation: See if you can add gap calculations to your results and sort the table by test accuracy to find the best models more efficiently. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d49f32",
   "metadata": {},
   "source": [
    "### Section 7. Conclusions and Insights\n",
    "\n",
    "# Using both your results and the results from others, which options are performing well and why do you think so. \n",
    "\n",
    "# This is your value as an analyst - narrate your story, link to other notebooks, provide a comprehensive view of what you feel is the best model for predicting quality in red wine. Base all your reasoning on data. Feel free to tune parameters if you like.  Discuss the types of models and why you think some seem to be more helpful. List the next steps you'd like to try if you were in a competition to build the best predictor. \n",
    "\n",
    "# Don't just copy code and don't just copy AI insights - use them to learn, but we all get them for free. Use all your tools to provide your own unique value and insights. Professional communication skills are critical. Evaluate your work in the context of others - how well can you craft a unique data story and present a compelling project to your clients / readers / self. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff18b4",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "Cortez, P., Cerdeira, A., Almeida, F., Matos, T., & Reis, J. (2009). Modeling wine preferences by data mining from physicochemical properties. _Decision Support Systems_, _47_(4), 547–553. https://doi.org/10.1016/j.dss.2009.05.016 <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
