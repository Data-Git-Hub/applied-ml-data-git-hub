{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Confusion Matrix Predict Next-Day Rain in Australia\n",
    "\n",
    "Author: Data-Git-Hub <br>\n",
    "GitHub Project Repository Link: https://github.com/Data-Git-Hub/applied-ml-data-git-hub <br>\n",
    "Kaggle Link: https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package <br>\n",
    "17 March 2025 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In this project, we will construct a Binary Confusion Matrix to evaluate the performance of a classification model using the weatherAUS.csv dataset from Kaggle. The dataset contains weather-related variables collected in Australia. For this analysis, we will focus solely on the last two columns of the dataset, which represent the actual and predicted classifications of a binary event—whether or not it rained the next day and limiting our sample size to only 1000 records. <br>\n",
    "\n",
    "A Confusion Matrix is a fundamental tool used in classification problems to summarize model performance by comparing predicted and actual outcomes. It consists of four key components: <br>\n",
    "\n",
    "True Positives (TP): Instances where the model correctly predicts a positive class (rain predicted and it actually rained). <br>\n",
    "False Positives (FP): Instances where the model incorrectly predicts a positive class (rain predicted, but it did not rain). <br>\n",
    "False Negatives (FN): Cases where the model fails to predict the positive class (rain not predicted, but it actually rained). <br>\n",
    "True Negatives (TN): Cases where the model correctly predicts a negative class (rain not predicted, and it did not rain). <br>\n",
    "\n",
    "In this context, the Actual Positives (P) represent the cases where rain actually occurred, while the Actual Negatives (N) represent cases where it did not rain. By analyzing the distribution of these values in the confusion matrix, we can assess the accuracy and reliability of the predictive model. <br>\n",
    "\n",
    "This project will involve: <br>\n",
    "\n",
    "- Extracting the relevant data columns from the dataset. <br>\n",
    "- Constructing a Binary Confusion Matrix based on the actual and predicted values. <br>\n",
    "- Analyzing model performance using standard evaluation metrics derived from the confusion matrix. <br>\n",
    "\n",
    "By the end of this analysis, we will have a clearer understanding of how well the model distinguishes between rainy and non-rainy days, providing insight into its effectiveness for weather prediction. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Python libraries are collections of pre-written code that provide specific functionalities, making programming more efficient and reducing the need to write code from scratch. These libraries cover a wide range of applications, including data analysis, machine learning, web development, and automation. Some libraries, such as os, sys, math, json, and datetime, come built-in with Python as part of its standard library, providing essential functions for file handling, system operations, mathematical computations, and data serialization. Other popular third-party libraries, like pandas, numpy, matplotlib, seaborn, and scikit-learn, must be installed separately and are widely used in data science and machine learning. The extensive availability of libraries in Python's ecosystem makes it a versatile and powerful programming language for various domains. <br>\n",
    "\n",
    "Pandas is a powerful data manipulation and analysis library that provides flexible data structures, such as DataFrames and Series. It is widely used for handling structured datasets, enabling easy data cleaning, transformation, and aggregation. Pandas is essential for data preprocessing in machine learning and statistical analysis. <br>\n",
    "https://pandas.pydata.org/docs/ <br>\n",
    "\n",
    "NumPy (Numerical Python) is a foundational library for numerical computing in Python. It provides support for large, multi-dimensional arrays and matrices, along with a comprehensive collection of mathematical functions to operate on these arrays efficiently. NumPy is a key component in scientific computing and machine learning. <br>\n",
    "https://numpy.org/doc/stable/ <br>\n",
    "\n",
    "Matplotlib is a widely used data visualization library that allows users to create static, animated, and interactive plots. It provides extensive tools for generating various chart types, including line plots, scatter plots, histograms, and bar charts, making it a critical library for exploratory data analysis. <br>\n",
    "https://matplotlib.org/stable/contents.html <br>\n",
    "\n",
    "Seaborn is a statistical data visualization library built on top of Matplotlib, designed for creating visually appealing and informative plots. It simplifies complex visualizations, such as heatmaps, violin plots, and pair plots, making it easier to identify patterns and relationships in datasets. <br>\n",
    "https://seaborn.pydata.org/ <br>\n",
    "\n",
    "Scikit-learn provides a variety of tools for machine learning, including data preprocessing, model selection, and evaluation. It contains essential functions for building predictive models and analyzing datasets. <br>\n",
    "sklearn.metrics: This module provides various performance metrics for evaluating machine learning models. <br>\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "# Data handling and manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning utilities\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Display settings\n",
    "%matplotlib inline\n",
    "\n",
    "file_path = \"C:/Projects/applied-ml-data-git-hub/D3/Data/weatherAUS.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "# Select only the last two columns\n",
    "df = df.iloc[:, -2:]  # Assuming last two columns contain actual and predicted values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Outline\n",
    "This project systematically analyzes the weatherAUS dataset and constructs a Binary Confusion Matrix to evaluate the performance of a predictive model. By following a structured workflow, we ensure a thorough understanding of the data and an accurate assessment of the model's ability to classify rainy and non-rainy days. <br>\n",
    "\n",
    "#### Section 1: Load and Explore the Data (Base Model)\n",
    "The first step is to load the weatherAUS dataset from its file path (D3/Data/weatherAUS.csv) and examine its structure. This includes: <br>\n",
    "\n",
    "Reading the dataset using pandas. <br>\n",
    "Inspecting column names, data types, and the number of missing values. <br>\n",
    "Displaying a basic statistical summary to understand data distribution. <br>\n",
    "This foundational step ensures that we understand the dataset before building our model. <br>\n",
    "\n",
    "#### Section 2: Data Preprocessing (Base Model)\n",
    "Since we are only using the last two columns, we will: <br>\n",
    "\n",
    "Extract the relevant columns representing actual and predicted values. <br>\n",
    "Handle any missing or inconsistent data entries. <br>\n",
    "Convert categorical values (if necessary) into numerical representations. <br>\n",
    "Cleaning the dataset ensures that the confusion matrix calculation is accurate. <br>\n",
    "\n",
    "#### Section 3: Constructing the Binary Confusion Matrix (Base Model)\n",
    "Using sklearn.metrics, we will generate a Binary Confusion Matrix that summarizes the model’s performance. This matrix will show: <br>\n",
    "\n",
    "True Positives (TP): Correctly predicted rainy days. <br>\n",
    "False Positives (FP): Incorrectly predicted rainy days. <br>\n",
    "False Negatives (FN): Missed rainy days. <br>\n",
    "True Negatives (TN): Correctly predicted non-rainy days. <br>\n",
    "This confusion matrix will be visualized using Seaborn’s heatmap, making it easier to interpret model performance. <br>\n",
    "\n",
    "#### Section 4: Model Evaluation Metrics\n",
    "To assess the effectiveness of our model, we will calculate key performance metrics derived from the confusion matrix: <br>\n",
    "\n",
    "- Base Model Evaluation <br>\n",
    "    Accuracy = (TP + TN) / (TP + TN + FP + FN) <br>\n",
    "    Precision = TP / (TP + FP) (How many predicted rainy days were correct?) <br>\n",
    "    Recall (Sensitivity) = TP / (TP + FN) (How well did the model capture actual rainy days?) <br>\n",
    "    F1-score = Harmonic mean of Precision and Recall. <br>\n",
    "    This baseline performance provides a reference point for improvement. <br>\n",
    "\n",
    "- Raise the Bar Model <br>\n",
    "    To enhance the model's performance, we will explore: <br>\n",
    "\n",
    "    Feature Engineering: Adding additional weather attributes (e.g., humidity, wind speed) to improve classification. <br>\n",
    "    Threshold Optimization: Adjusting the probability threshold for predicting rain to reduce false positives or false negatives. <br>\n",
    "    Advanced Models: Exploring machine learning algorithms beyond a simple threshold-based classifier, such as Logistic Regression or Decision Trees. <br>\n",
    "\n",
    "- Lower the Bar Model <br>\n",
    "    To compare against a weaker alternative, we will: <br>\n",
    "\n",
    "    Use a Naïve Baseline Approach: Randomly predicting \"rain\" or \"no rain\" based on overall dataset proportions. <br>\n",
    "    Ignore Preprocessing: Using raw data without handling missing values or categorical transformations. <br>\n",
    "    Fixed Thresholds Without Optimization: Sticking to an arbitrary classification threshold without adjustment. <br>\n",
    "    By contrasting the Raise the Bar Model and Lower the Bar Model against the Base Model, we gain deeper insights into what contributes to a stronger predictive model. <br>\n",
    "\n",
    "#### Section 5: Conclusion and Next Steps (Base Model, Raise the Bar Model, Lower the Bar Model)\n",
    "The final section will summarize findings, highlighting: <br>\n",
    "\n",
    "The effectiveness of the base model in predicting rainy days. <br>\n",
    "How performance improved in the Raise the Bar Model. <br>\n",
    "The limitations observed in the Lower the Bar Model. <br>\n",
    "\n",
    "Potential improvements, such as adjusting decision thresholds or using more advanced models. <br>\n",
    "By following this structured approach, we ensure that our Binary Confusion Matrix accurately represents the model’s performance, guiding data-driven improvements. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1. Load and Explore the Data (Base Model)\n",
    "- Limit the data to 1000 sample size and clean the data to ensure NAN, null, and the data is binary. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First ten rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RainToday RainTomorrow\n",
       "0        No           No\n",
       "1        No           No\n",
       "2        No           No\n",
       "3        No           No\n",
       "4        No           No\n",
       "5        No           No\n",
       "6        No           No\n",
       "7        No           No\n",
       "8        No          Yes\n",
       "9       Yes           No"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column names in the dataset:\n",
      "['RainToday', 'RainTomorrow']\n",
      "\n",
      "Missing values in each column:\n",
      "RainToday       3261\n",
      "RainTomorrow    3267\n",
      "\n",
      "Dataset info after cleaning and selection:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 0 to 1024\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Actual     1000 non-null   object\n",
      " 1   Predicted  1000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 23.4+ KB\n",
      "\n",
      "Summary statistics of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>773</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Predicted\n",
       "count    1000      1000\n",
       "unique      2         2\n",
       "top        No        No\n",
       "freq      773       773"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display basic dataset structure\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "pd.set_option(\"display.expand_frame_repr\", False)  # Prevent column wrapping\n",
    "\n",
    "# Display first few rows\n",
    "print(\"First ten rows of the dataset:\")\n",
    "display(df.head(10))  # Using display() for better rendering in Jupyter\n",
    "\n",
    "# Display column names\n",
    "print(\"\\nColumn names in the dataset:\")\n",
    "print(df.columns.to_list())  # Converts to list for better readability\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum().to_string())  # Prevent truncation\n",
    "\n",
    "# Select only the last two columns\n",
    "df = df.iloc[:, -2:]  # Assuming last two columns contain actual and predicted values\n",
    "\n",
    "# Rename columns for clarity (if necessary)\n",
    "df.columns = [\"Actual\", \"Predicted\"]\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Limit to the first 1,000 data pairs\n",
    "df = df.head(1000)\n",
    "\n",
    "# Display dataset info after cleaning\n",
    "print(\"\\nDataset info after cleaning and selection:\")\n",
    "df.info()  # Prints a summary of dataset structure\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary statistics of the dataset:\")\n",
    "display(df.describe())  # Using display() for better Jupyter output formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Data Preprocessing (Base Model)\n",
    "- Conversion of Data to boolean formatting for machine learning compatibility.\n",
    "- Verification of binary 0 and 1 remains in both columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in 'Actual' column after conversion: [0 1]\n",
      "Unique values in 'Predicted' column after conversion: [0 1]\n",
      "\n",
      "Final dataset shape after preprocessing: (1000, 2)\n",
      "\n",
      "First ten rows of preprocessed dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predicted\n",
       "0       0          0\n",
       "1       0          0\n",
       "2       0          0\n",
       "3       0          0\n",
       "4       0          0\n",
       "5       0          0\n",
       "6       0          0\n",
       "7       0          0\n",
       "8       0          1\n",
       "9       1          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert categorical values to numerical (if applicable)\n",
    "df[\"Actual\"] = df[\"Actual\"].map({\"No\": 0, \"Yes\": 1})\n",
    "df[\"Predicted\"] = df[\"Predicted\"].map({\"No\": 0, \"Yes\": 1})\n",
    "\n",
    "# Drop any remaining NaN values after conversion\n",
    "df = df.dropna()\n",
    "\n",
    "# Ensure the dataset only contains binary values (0 and 1)\n",
    "valid_values = [0, 1]\n",
    "df = df[df[\"Actual\"].isin(valid_values) & df[\"Predicted\"].isin(valid_values)]\n",
    "\n",
    "# Display unique values to verify\n",
    "print(\"\\nUnique values in 'Actual' column after conversion:\", df[\"Actual\"].unique())\n",
    "print(\"Unique values in 'Predicted' column after conversion:\", df[\"Predicted\"].unique())\n",
    "\n",
    "# Verify the final shape of the dataset\n",
    "print(\"\\nFinal dataset shape after preprocessing:\", df.shape)\n",
    "\n",
    "# Display first few rows to confirm successful preprocessing\n",
    "print(\"\\nFirst ten rows of preprocessed dataset:\")\n",
    "display(df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Constructing the Binary Confusion Matrix (Base Model)\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
